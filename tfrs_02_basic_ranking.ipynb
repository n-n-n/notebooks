{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tfrs_02_basic_ranking.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/n-n-n/notebooks/blob/main/tfrs_02_basic_ranking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X80i_girFR2o"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "bB8gHCR3FVC0"
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCeYA79m1DEX"
      },
      "source": [
        "# Recommending movies: ranking\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/recommenders/examples/basic_ranking\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/recommenders/blob/main/docs/examples/basic_ranking.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/recommenders/blob/main/docs/examples/basic_ranking.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/recommenders/docs/examples/basic_ranking.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
        "  </td>\n",
        "</table>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gf2jMHkZQYB5"
      },
      "source": [
        "Real-world recommender systems are often composed of two stages:\n",
        "\n",
        "1. The retrieval stage is responsible for selecting an initial set of hundreds of candidates from all possible candidates. The main objective of this model is to efficiently weed out all candidates that the user is not interested in. Because the retrieval model may be dealing with millions of candidates, it has to be computationally efficient.\n",
        "2. The ranking stage takes the outputs of the retrieval model and fine-tunes them to select the best possible handful of recommendations. Its task is to narrow down the set of items the user may be interested in to a shortlist of likely candidates.\n",
        "\n",
        "We're going to focus on the second stage, ranking. If you are interested in the retrieval stage, have a look at our [retrieval](basic_retrieval) tutorial.\n",
        "\n",
        "In this tutorial, we're going to:\n",
        "\n",
        "1. Get our data and split it into a training and test set.\n",
        "2. Implement a ranking model.\n",
        "3. Fit and evaluate it.\n",
        "\n",
        "\n",
        "## Imports\n",
        "\n",
        "\n",
        "Let's first get our imports out of the way."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gG3jLOGbaUv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2ae5e16-dbd6-41cc-d708-f623b7f5e911"
      },
      "source": [
        "!pip install -q tensorflow-recommenders\n",
        "!pip install -q --upgrade tensorflow-datasets"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 81kB 3.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.9MB 5.4MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZGYDaF-m5wZ"
      },
      "source": [
        "import os\n",
        "import pprint\n",
        "import tempfile\n",
        "\n",
        "from typing import Dict, Text\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxQ_hy7xPH3N"
      },
      "source": [
        "import tensorflow_recommenders as tfrs"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PAqjR4a1RR4"
      },
      "source": [
        "## Preparing the dataset\n",
        "\n",
        "We're going to use the same data as the [retrieval](basic_retrieval) tutorial. This time, we're also going to keep the ratings: these are the objectives we are trying to predict."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaQhqcLGP0jL"
      },
      "source": [
        "ratings = tfds.load(\"movielens/100k-ratings\", split=\"train\")\n",
        "\n",
        "ratings_mapped = ratings.map(lambda x: {\n",
        "    \"movie_title\": x[\"movie_title\"],\n",
        "    \"user_id\": x[\"user_id\"],\n",
        "    \"user_rating\": x[\"user_rating\"]\n",
        "})"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iu4XSa_G1nyN"
      },
      "source": [
        "As before, we'll split the data by putting 80% of the ratings in the train set, and 20% in the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rS0eDfkjnjJL"
      },
      "source": [
        "tf.random.set_seed(42)\n",
        "shuffled = ratings_mapped.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
        "\n",
        "train = shuffled.take(80_000)\n",
        "test = shuffled.skip(80_000).take(20_000)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVi1HJfR9D7H"
      },
      "source": [
        "Let's also figure out unique user ids and movie titles present in the data. \n",
        "\n",
        "This is important because we need to be able to map the raw values of our categorical features to embedding vectors in our models. To do that, we need a vocabulary that maps a raw feature value to an integer in a contiguous range: this allows us to look up the corresponding embeddings in our embedding tables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKROCiPo_5LJ"
      },
      "source": [
        "movie_titles = ratings_mapped.batch(1_000_000).map(lambda x: x[\"movie_title\"])\n",
        "user_ids = ratings_mapped.batch(1_000_000).map(lambda x: x[\"user_id\"])\n",
        "\n",
        "unique_movie_titles = np.unique(np.concatenate(list(movie_titles)))\n",
        "unique_user_ids = np.unique(np.concatenate(list(user_ids)))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-Vj9nHb48pn"
      },
      "source": [
        "## Implementing a model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCi-seR86qqa"
      },
      "source": [
        "### Architecture\n",
        "\n",
        "Ranking models do not face the same efficiency constraints as retrieval models do, and so we have a little bit more freedom in our choice of architectures.\n",
        "\n",
        "A model composed of multiple stacked dense layers is a relatively common architecture for ranking tasks. We can implement it as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAk0y0Yf1eGh"
      },
      "source": [
        "class RankingModel(tf.keras.Model):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    embedding_dimension = 32\n",
        "\n",
        "    # Compute embeddings for users.\n",
        "    self.user_embeddings = tf.keras.Sequential([\n",
        "      tf.keras.layers.experimental.preprocessing.StringLookup(\n",
        "        vocabulary=unique_user_ids, mask_token=None),\n",
        "      tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
        "    ])\n",
        "\n",
        "    # Compute embeddings for movies.\n",
        "    self.movie_embeddings = tf.keras.Sequential([\n",
        "      tf.keras.layers.experimental.preprocessing.StringLookup(\n",
        "        vocabulary=unique_movie_titles, mask_token=None),\n",
        "      tf.keras.layers.Embedding(len(unique_movie_titles) + 1, embedding_dimension)\n",
        "    ])\n",
        "\n",
        "    # Compute predictions.\n",
        "    self.ratings = tf.keras.Sequential([\n",
        "      # Learn multiple dense layers.\n",
        "      tf.keras.layers.Dense(256, activation=\"relu\"),\n",
        "      tf.keras.layers.Dense(64, activation=\"relu\"),\n",
        "      # Make rating predictions in the final layer.\n",
        "      tf.keras.layers.Dense(1)\n",
        "  ])\n",
        "    \n",
        "  def call(self, inputs):\n",
        "\n",
        "    user_id, movie_title = inputs\n",
        "\n",
        "    user_embedding = self.user_embeddings(user_id)\n",
        "    movie_embedding = self.movie_embeddings(movie_title)\n",
        "\n",
        "    return self.ratings(tf.concat([user_embedding, movie_embedding], axis=1))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g76wZt-s2WmS"
      },
      "source": [
        "This model takes user ids and movie titles, and outputs a predicted rating:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVxiAsRE2I8J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b140b089-c86c-45ec-854b-dff167e4e198"
      },
      "source": [
        "RankingModel()(([\"42\"], [\"One Flew Over the Cuckoo's Nest (1975)\"]))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'list'> input: ['42']\n",
            "Consider rewriting this model with the Functional API.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'list'> input: ['42']\n",
            "Consider rewriting this model with the Functional API.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'list'> input: [\"One Flew Over the Cuckoo's Nest (1975)\"]\n",
            "Consider rewriting this model with the Functional API.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'list'> input: [\"One Flew Over the Cuckoo's Nest (1975)\"]\n",
            "Consider rewriting this model with the Functional API.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-0.0221471]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCaCqJsXSkCo"
      },
      "source": [
        "### Loss and metrics\n",
        "\n",
        "The next component is the loss used to train our model. TFRS has several loss layers and tasks to make this easy.\n",
        "\n",
        "In this instance, we'll make use of the `Ranking` task object: a convenience wrapper that bundles together the loss function and metric computation. \n",
        "\n",
        "We'll use it together with the `MeanSquaredError` Keras loss in order to predict the ratings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJ61Iz2QTBw3"
      },
      "source": [
        "task = tfrs.tasks.Ranking(\n",
        "  loss = tf.keras.losses.MeanSquaredError(),\n",
        "  metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
        ")"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-3xFC-1cbz0"
      },
      "source": [
        "The task itself is a Keras layer that takes true and predicted as arguments, and returns the computed loss. We'll use that to implement the model's training loop."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZUFeSlWRHGx"
      },
      "source": [
        "### The full model\n",
        "\n",
        "We can now put it all together into a model. TFRS exposes a base model class (`tfrs.models.Model`) which streamlines bulding models: all we need to do is to set up the components in the `__init__` method, and implement the `compute_loss` method, taking in the raw features and returning a loss value.\n",
        "\n",
        "The base model will then take care of creating the appropriate training loop to fit our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8n7c5CHFp0ow"
      },
      "source": [
        "class MovielensModel(tfrs.models.Model):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.ranking_model: tf.keras.Model = RankingModel()\n",
        "    self.task: tf.keras.layers.Layer = tfrs.tasks.Ranking(\n",
        "      loss = tf.keras.losses.MeanSquaredError(),\n",
        "      metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
        "    )\n",
        "\n",
        "  def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
        "    rating_predictions = self.ranking_model(\n",
        "        (features[\"user_id\"], features[\"movie_title\"]))\n",
        "\n",
        "    # The task computes the loss and the metrics.\n",
        "    return self.task(labels=features[\"user_rating\"], predictions=rating_predictions)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDN_LJGlnRGo"
      },
      "source": [
        "## Fitting and evaluating\n",
        "\n",
        "After defining the model, we can use standard Keras fitting and evaluation routines to fit and evaluate the model.\n",
        "\n",
        "Let's first instantiate the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aW63YaqP2wCf"
      },
      "source": [
        "model = MovielensModel()\n",
        "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nma0vc2XdN5g"
      },
      "source": [
        "Then shuffle, batch, and cache the training and evaluation data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53QJwY1gUnfv"
      },
      "source": [
        "cached_train = train.shuffle(100_000).batch(8192).cache()\n",
        "cached_test = test.batch(4096).cache()"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8mHTxKAdTJO"
      },
      "source": [
        "Then train the  model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxPntlT8EFOZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95d2ab0e-2e6b-4576-80d4-762d3a951991"
      },
      "source": [
        "model.fit(cached_train, epochs=100)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "10/10 [==============================] - 1s 57ms/step - root_mean_squared_error: 0.9470 - loss: 0.8947 - regularization_loss: 0.0000e+00 - total_loss: 0.8947\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 1s 52ms/step - root_mean_squared_error: 0.9420 - loss: 0.8853 - regularization_loss: 0.0000e+00 - total_loss: 0.8853\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 1s 54ms/step - root_mean_squared_error: 0.9380 - loss: 0.8777 - regularization_loss: 0.0000e+00 - total_loss: 0.8777\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 1s 53ms/step - root_mean_squared_error: 0.9348 - loss: 0.8716 - regularization_loss: 0.0000e+00 - total_loss: 0.8716\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 1s 54ms/step - root_mean_squared_error: 0.9328 - loss: 0.8678 - regularization_loss: 0.0000e+00 - total_loss: 0.8678\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 1s 54ms/step - root_mean_squared_error: 0.9397 - loss: 0.8820 - regularization_loss: 0.0000e+00 - total_loss: 0.8820\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 1s 53ms/step - root_mean_squared_error: 0.9487 - loss: 0.8947 - regularization_loss: 0.0000e+00 - total_loss: 0.8947\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 1s 56ms/step - root_mean_squared_error: 0.9301 - loss: 0.8622 - regularization_loss: 0.0000e+00 - total_loss: 0.8622\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 1s 53ms/step - root_mean_squared_error: 0.9257 - loss: 0.8548 - regularization_loss: 0.0000e+00 - total_loss: 0.8548\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - 1s 52ms/step - root_mean_squared_error: 0.9243 - loss: 0.8522 - regularization_loss: 0.0000e+00 - total_loss: 0.8522\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - 1s 52ms/step - root_mean_squared_error: 0.9233 - loss: 0.8504 - regularization_loss: 0.0000e+00 - total_loss: 0.8504\n",
            "Epoch 12/100\n",
            "10/10 [==============================] - 1s 52ms/step - root_mean_squared_error: 0.9225 - loss: 0.8488 - regularization_loss: 0.0000e+00 - total_loss: 0.8488\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - 1s 53ms/step - root_mean_squared_error: 0.9217 - loss: 0.8474 - regularization_loss: 0.0000e+00 - total_loss: 0.8474\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - 1s 51ms/step - root_mean_squared_error: 0.9211 - loss: 0.8463 - regularization_loss: 0.0000e+00 - total_loss: 0.8463\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - 1s 53ms/step - root_mean_squared_error: 0.9207 - loss: 0.8455 - regularization_loss: 0.0000e+00 - total_loss: 0.8455\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - 1s 51ms/step - root_mean_squared_error: 0.9208 - loss: 0.8455 - regularization_loss: 0.0000e+00 - total_loss: 0.8455\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - 1s 53ms/step - root_mean_squared_error: 0.9218 - loss: 0.8472 - regularization_loss: 0.0000e+00 - total_loss: 0.8472\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - 1s 53ms/step - root_mean_squared_error: 0.9235 - loss: 0.8501 - regularization_loss: 0.0000e+00 - total_loss: 0.8501\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - 1s 53ms/step - root_mean_squared_error: 0.9232 - loss: 0.8493 - regularization_loss: 0.0000e+00 - total_loss: 0.8493\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - 1s 52ms/step - root_mean_squared_error: 0.9209 - loss: 0.8454 - regularization_loss: 0.0000e+00 - total_loss: 0.8454\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - 1s 52ms/step - root_mean_squared_error: 0.9193 - loss: 0.8426 - regularization_loss: 0.0000e+00 - total_loss: 0.8426\n",
            "Epoch 22/100\n",
            "10/10 [==============================] - 1s 53ms/step - root_mean_squared_error: 0.9185 - loss: 0.8413 - regularization_loss: 0.0000e+00 - total_loss: 0.8413\n",
            "Epoch 23/100\n",
            "10/10 [==============================] - 1s 55ms/step - root_mean_squared_error: 0.9180 - loss: 0.8406 - regularization_loss: 0.0000e+00 - total_loss: 0.8406\n",
            "Epoch 24/100\n",
            "10/10 [==============================] - 1s 53ms/step - root_mean_squared_error: 0.9178 - loss: 0.8401 - regularization_loss: 0.0000e+00 - total_loss: 0.8401\n",
            "Epoch 25/100\n",
            "10/10 [==============================] - 1s 52ms/step - root_mean_squared_error: 0.9176 - loss: 0.8397 - regularization_loss: 0.0000e+00 - total_loss: 0.8397\n",
            "Epoch 26/100\n",
            "10/10 [==============================] - 1s 52ms/step - root_mean_squared_error: 0.9174 - loss: 0.8393 - regularization_loss: 0.0000e+00 - total_loss: 0.8393\n",
            "Epoch 27/100\n",
            "10/10 [==============================] - 0s 49ms/step - root_mean_squared_error: 0.9172 - loss: 0.8390 - regularization_loss: 0.0000e+00 - total_loss: 0.8390\n",
            "Epoch 28/100\n",
            "10/10 [==============================] - 1s 56ms/step - root_mean_squared_error: 0.9171 - loss: 0.8387 - regularization_loss: 0.0000e+00 - total_loss: 0.8387\n",
            "Epoch 29/100\n",
            "10/10 [==============================] - 1s 52ms/step - root_mean_squared_error: 0.9170 - loss: 0.8385 - regularization_loss: 0.0000e+00 - total_loss: 0.8385\n",
            "Epoch 30/100\n",
            "10/10 [==============================] - 1s 53ms/step - root_mean_squared_error: 0.9169 - loss: 0.8383 - regularization_loss: 0.0000e+00 - total_loss: 0.8383\n",
            "Epoch 31/100\n",
            "10/10 [==============================] - 0s 50ms/step - root_mean_squared_error: 0.9168 - loss: 0.8382 - regularization_loss: 0.0000e+00 - total_loss: 0.8382\n",
            "Epoch 32/100\n",
            "10/10 [==============================] - 0s 49ms/step - root_mean_squared_error: 0.9167 - loss: 0.8380 - regularization_loss: 0.0000e+00 - total_loss: 0.8380\n",
            "Epoch 33/100\n",
            "10/10 [==============================] - 1s 53ms/step - root_mean_squared_error: 0.9166 - loss: 0.8377 - regularization_loss: 0.0000e+00 - total_loss: 0.8377\n",
            "Epoch 34/100\n",
            "10/10 [==============================] - 1s 49ms/step - root_mean_squared_error: 0.9165 - loss: 0.8375 - regularization_loss: 0.0000e+00 - total_loss: 0.8375\n",
            "Epoch 35/100\n",
            "10/10 [==============================] - 1s 54ms/step - root_mean_squared_error: 0.9163 - loss: 0.8372 - regularization_loss: 0.0000e+00 - total_loss: 0.8372\n",
            "Epoch 36/100\n",
            "10/10 [==============================] - 1s 56ms/step - root_mean_squared_error: 0.9162 - loss: 0.8369 - regularization_loss: 0.0000e+00 - total_loss: 0.8369\n",
            "Epoch 37/100\n",
            "10/10 [==============================] - 1s 53ms/step - root_mean_squared_error: 0.9160 - loss: 0.8366 - regularization_loss: 0.0000e+00 - total_loss: 0.8366\n",
            "Epoch 38/100\n",
            "10/10 [==============================] - 1s 53ms/step - root_mean_squared_error: 0.9159 - loss: 0.8364 - regularization_loss: 0.0000e+00 - total_loss: 0.8364\n",
            "Epoch 39/100\n",
            "10/10 [==============================] - 1s 53ms/step - root_mean_squared_error: 0.9157 - loss: 0.8361 - regularization_loss: 0.0000e+00 - total_loss: 0.8361\n",
            "Epoch 40/100\n",
            "10/10 [==============================] - 1s 53ms/step - root_mean_squared_error: 0.9156 - loss: 0.8359 - regularization_loss: 0.0000e+00 - total_loss: 0.8359\n",
            "Epoch 41/100\n",
            "10/10 [==============================] - 1s 54ms/step - root_mean_squared_error: 0.9155 - loss: 0.8357 - regularization_loss: 0.0000e+00 - total_loss: 0.8357\n",
            "Epoch 42/100\n",
            "10/10 [==============================] - 1s 53ms/step - root_mean_squared_error: 0.9154 - loss: 0.8355 - regularization_loss: 0.0000e+00 - total_loss: 0.8355\n",
            "Epoch 43/100\n",
            "10/10 [==============================] - 1s 55ms/step - root_mean_squared_error: 0.9153 - loss: 0.8352 - regularization_loss: 0.0000e+00 - total_loss: 0.8352\n",
            "Epoch 44/100\n",
            "10/10 [==============================] - 1s 53ms/step - root_mean_squared_error: 0.9151 - loss: 0.8350 - regularization_loss: 0.0000e+00 - total_loss: 0.8350\n",
            "Epoch 45/100\n",
            "10/10 [==============================] - 1s 57ms/step - root_mean_squared_error: 0.9150 - loss: 0.8348 - regularization_loss: 0.0000e+00 - total_loss: 0.8348\n",
            "Epoch 46/100\n",
            "10/10 [==============================] - 1s 56ms/step - root_mean_squared_error: 0.9149 - loss: 0.8346 - regularization_loss: 0.0000e+00 - total_loss: 0.8346\n",
            "Epoch 47/100\n",
            "10/10 [==============================] - 1s 55ms/step - root_mean_squared_error: 0.9148 - loss: 0.8344 - regularization_loss: 0.0000e+00 - total_loss: 0.8344\n",
            "Epoch 48/100\n",
            "10/10 [==============================] - 1s 56ms/step - root_mean_squared_error: 0.9147 - loss: 0.8343 - regularization_loss: 0.0000e+00 - total_loss: 0.8343\n",
            "Epoch 49/100\n",
            "10/10 [==============================] - 1s 52ms/step - root_mean_squared_error: 0.9147 - loss: 0.8341 - regularization_loss: 0.0000e+00 - total_loss: 0.8341\n",
            "Epoch 50/100\n",
            "10/10 [==============================] - 1s 53ms/step - root_mean_squared_error: 0.9146 - loss: 0.8339 - regularization_loss: 0.0000e+00 - total_loss: 0.8339\n",
            "Epoch 51/100\n",
            "10/10 [==============================] - 1s 52ms/step - root_mean_squared_error: 0.9145 - loss: 0.8337 - regularization_loss: 0.0000e+00 - total_loss: 0.8337\n",
            "Epoch 52/100\n",
            "10/10 [==============================] - 1s 53ms/step - root_mean_squared_error: 0.9144 - loss: 0.8336 - regularization_loss: 0.0000e+00 - total_loss: 0.8336\n",
            "Epoch 53/100\n",
            "10/10 [==============================] - 1s 56ms/step - root_mean_squared_error: 0.9143 - loss: 0.8334 - regularization_loss: 0.0000e+00 - total_loss: 0.8334\n",
            "Epoch 54/100\n",
            "10/10 [==============================] - 1s 53ms/step - root_mean_squared_error: 0.9142 - loss: 0.8332 - regularization_loss: 0.0000e+00 - total_loss: 0.8332\n",
            "Epoch 55/100\n",
            "10/10 [==============================] - 1s 53ms/step - root_mean_squared_error: 0.9141 - loss: 0.8330 - regularization_loss: 0.0000e+00 - total_loss: 0.8330\n",
            "Epoch 56/100\n",
            "10/10 [==============================] - 1s 54ms/step - root_mean_squared_error: 0.9140 - loss: 0.8328 - regularization_loss: 0.0000e+00 - total_loss: 0.8328\n",
            "Epoch 57/100\n",
            "10/10 [==============================] - 1s 54ms/step - root_mean_squared_error: 0.9139 - loss: 0.8327 - regularization_loss: 0.0000e+00 - total_loss: 0.8327\n",
            "Epoch 58/100\n",
            "10/10 [==============================] - 1s 54ms/step - root_mean_squared_error: 0.9138 - loss: 0.8325 - regularization_loss: 0.0000e+00 - total_loss: 0.8325\n",
            "Epoch 59/100\n",
            "10/10 [==============================] - 1s 53ms/step - root_mean_squared_error: 0.9137 - loss: 0.8323 - regularization_loss: 0.0000e+00 - total_loss: 0.8323\n",
            "Epoch 60/100\n",
            "10/10 [==============================] - 1s 56ms/step - root_mean_squared_error: 0.9136 - loss: 0.8321 - regularization_loss: 0.0000e+00 - total_loss: 0.8321\n",
            "Epoch 61/100\n",
            "10/10 [==============================] - 1s 52ms/step - root_mean_squared_error: 0.9135 - loss: 0.8319 - regularization_loss: 0.0000e+00 - total_loss: 0.8319\n",
            "Epoch 62/100\n",
            "10/10 [==============================] - 1s 53ms/step - root_mean_squared_error: 0.9134 - loss: 0.8317 - regularization_loss: 0.0000e+00 - total_loss: 0.8317\n",
            "Epoch 63/100\n",
            "10/10 [==============================] - 1s 53ms/step - root_mean_squared_error: 0.9133 - loss: 0.8315 - regularization_loss: 0.0000e+00 - total_loss: 0.8315\n",
            "Epoch 64/100\n",
            "10/10 [==============================] - 1s 53ms/step - root_mean_squared_error: 0.9132 - loss: 0.8313 - regularization_loss: 0.0000e+00 - total_loss: 0.8313\n",
            "Epoch 65/100\n",
            "10/10 [==============================] - 1s 53ms/step - root_mean_squared_error: 0.9131 - loss: 0.8311 - regularization_loss: 0.0000e+00 - total_loss: 0.8311\n",
            "Epoch 66/100\n",
            "10/10 [==============================] - 1s 51ms/step - root_mean_squared_error: 0.9130 - loss: 0.8309 - regularization_loss: 0.0000e+00 - total_loss: 0.8309\n",
            "Epoch 67/100\n",
            "10/10 [==============================] - 1s 54ms/step - root_mean_squared_error: 0.9129 - loss: 0.8307 - regularization_loss: 0.0000e+00 - total_loss: 0.8307\n",
            "Epoch 68/100\n",
            "10/10 [==============================] - 1s 55ms/step - root_mean_squared_error: 0.9128 - loss: 0.8305 - regularization_loss: 0.0000e+00 - total_loss: 0.8305\n",
            "Epoch 69/100\n",
            "10/10 [==============================] - 1s 53ms/step - root_mean_squared_error: 0.9126 - loss: 0.8303 - regularization_loss: 0.0000e+00 - total_loss: 0.8303\n",
            "Epoch 70/100\n",
            "10/10 [==============================] - 1s 58ms/step - root_mean_squared_error: 0.9125 - loss: 0.8301 - regularization_loss: 0.0000e+00 - total_loss: 0.8301\n",
            "Epoch 71/100\n",
            "10/10 [==============================] - 1s 54ms/step - root_mean_squared_error: 0.9124 - loss: 0.8298 - regularization_loss: 0.0000e+00 - total_loss: 0.8298\n",
            "Epoch 72/100\n",
            "10/10 [==============================] - 1s 54ms/step - root_mean_squared_error: 0.9123 - loss: 0.8296 - regularization_loss: 0.0000e+00 - total_loss: 0.8296\n",
            "Epoch 73/100\n",
            "10/10 [==============================] - 1s 56ms/step - root_mean_squared_error: 0.9121 - loss: 0.8294 - regularization_loss: 0.0000e+00 - total_loss: 0.8294\n",
            "Epoch 74/100\n",
            "10/10 [==============================] - 1s 54ms/step - root_mean_squared_error: 0.9120 - loss: 0.8291 - regularization_loss: 0.0000e+00 - total_loss: 0.8291\n",
            "Epoch 75/100\n",
            "10/10 [==============================] - 1s 56ms/step - root_mean_squared_error: 0.9119 - loss: 0.8289 - regularization_loss: 0.0000e+00 - total_loss: 0.8289\n",
            "Epoch 76/100\n",
            "10/10 [==============================] - 1s 53ms/step - root_mean_squared_error: 0.9117 - loss: 0.8286 - regularization_loss: 0.0000e+00 - total_loss: 0.8286\n",
            "Epoch 77/100\n",
            "10/10 [==============================] - 1s 54ms/step - root_mean_squared_error: 0.9116 - loss: 0.8284 - regularization_loss: 0.0000e+00 - total_loss: 0.8284\n",
            "Epoch 78/100\n",
            "10/10 [==============================] - 1s 55ms/step - root_mean_squared_error: 0.9115 - loss: 0.8281 - regularization_loss: 0.0000e+00 - total_loss: 0.8281\n",
            "Epoch 79/100\n",
            "10/10 [==============================] - 1s 53ms/step - root_mean_squared_error: 0.9113 - loss: 0.8278 - regularization_loss: 0.0000e+00 - total_loss: 0.8278\n",
            "Epoch 80/100\n",
            "10/10 [==============================] - 1s 54ms/step - root_mean_squared_error: 0.9112 - loss: 0.8276 - regularization_loss: 0.0000e+00 - total_loss: 0.8276\n",
            "Epoch 81/100\n",
            "10/10 [==============================] - 1s 52ms/step - root_mean_squared_error: 0.9110 - loss: 0.8273 - regularization_loss: 0.0000e+00 - total_loss: 0.8273\n",
            "Epoch 82/100\n",
            "10/10 [==============================] - 1s 52ms/step - root_mean_squared_error: 0.9109 - loss: 0.8270 - regularization_loss: 0.0000e+00 - total_loss: 0.8270\n",
            "Epoch 83/100\n",
            "10/10 [==============================] - 1s 53ms/step - root_mean_squared_error: 0.9107 - loss: 0.8267 - regularization_loss: 0.0000e+00 - total_loss: 0.8267\n",
            "Epoch 84/100\n",
            "10/10 [==============================] - 1s 53ms/step - root_mean_squared_error: 0.9106 - loss: 0.8264 - regularization_loss: 0.0000e+00 - total_loss: 0.8264\n",
            "Epoch 85/100\n",
            "10/10 [==============================] - 1s 55ms/step - root_mean_squared_error: 0.9104 - loss: 0.8261 - regularization_loss: 0.0000e+00 - total_loss: 0.8261\n",
            "Epoch 86/100\n",
            "10/10 [==============================] - 1s 55ms/step - root_mean_squared_error: 0.9102 - loss: 0.8258 - regularization_loss: 0.0000e+00 - total_loss: 0.8258\n",
            "Epoch 87/100\n",
            "10/10 [==============================] - 1s 57ms/step - root_mean_squared_error: 0.9101 - loss: 0.8255 - regularization_loss: 0.0000e+00 - total_loss: 0.8255\n",
            "Epoch 88/100\n",
            "10/10 [==============================] - 1s 55ms/step - root_mean_squared_error: 0.9099 - loss: 0.8252 - regularization_loss: 0.0000e+00 - total_loss: 0.8252\n",
            "Epoch 89/100\n",
            "10/10 [==============================] - 1s 55ms/step - root_mean_squared_error: 0.9097 - loss: 0.8249 - regularization_loss: 0.0000e+00 - total_loss: 0.8249\n",
            "Epoch 90/100\n",
            "10/10 [==============================] - 1s 55ms/step - root_mean_squared_error: 0.9096 - loss: 0.8245 - regularization_loss: 0.0000e+00 - total_loss: 0.8245\n",
            "Epoch 91/100\n",
            "10/10 [==============================] - 1s 56ms/step - root_mean_squared_error: 0.9094 - loss: 0.8242 - regularization_loss: 0.0000e+00 - total_loss: 0.8242\n",
            "Epoch 92/100\n",
            "10/10 [==============================] - 1s 55ms/step - root_mean_squared_error: 0.9092 - loss: 0.8239 - regularization_loss: 0.0000e+00 - total_loss: 0.8239\n",
            "Epoch 93/100\n",
            "10/10 [==============================] - 1s 54ms/step - root_mean_squared_error: 0.9091 - loss: 0.8236 - regularization_loss: 0.0000e+00 - total_loss: 0.8236\n",
            "Epoch 94/100\n",
            "10/10 [==============================] - 1s 54ms/step - root_mean_squared_error: 0.9089 - loss: 0.8233 - regularization_loss: 0.0000e+00 - total_loss: 0.8233\n",
            "Epoch 95/100\n",
            "10/10 [==============================] - 1s 55ms/step - root_mean_squared_error: 0.9088 - loss: 0.8230 - regularization_loss: 0.0000e+00 - total_loss: 0.8230\n",
            "Epoch 96/100\n",
            "10/10 [==============================] - 1s 53ms/step - root_mean_squared_error: 0.9086 - loss: 0.8226 - regularization_loss: 0.0000e+00 - total_loss: 0.8226\n",
            "Epoch 97/100\n",
            "10/10 [==============================] - 1s 55ms/step - root_mean_squared_error: 0.9084 - loss: 0.8223 - regularization_loss: 0.0000e+00 - total_loss: 0.8223\n",
            "Epoch 98/100\n",
            "10/10 [==============================] - 1s 54ms/step - root_mean_squared_error: 0.9082 - loss: 0.8219 - regularization_loss: 0.0000e+00 - total_loss: 0.8219\n",
            "Epoch 99/100\n",
            "10/10 [==============================] - 1s 52ms/step - root_mean_squared_error: 0.9080 - loss: 0.8215 - regularization_loss: 0.0000e+00 - total_loss: 0.8215\n",
            "Epoch 100/100\n",
            "10/10 [==============================] - 1s 54ms/step - root_mean_squared_error: 0.9078 - loss: 0.8211 - regularization_loss: 0.0000e+00 - total_loss: 0.8211\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe05a1a0750>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsluR8audV9W"
      },
      "source": [
        "As the model trains, the loss is falling and the RMSE metric is improving."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Gxp5RLFcv64"
      },
      "source": [
        "Finally, we can evaluate our model on the test set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-zu6HLODNeI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b57db63-b3cd-451a-a2d2-d705cad0c54c"
      },
      "source": [
        "model.evaluate(cached_test, return_dict=True)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 0s 10ms/step - root_mean_squared_error: 0.9320 - loss: 0.8697 - regularization_loss: 0.0000e+00 - total_loss: 0.8697\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss': 0.8745973706245422,\n",
              " 'regularization_loss': 0,\n",
              " 'root_mean_squared_error': 0.9319667816162109,\n",
              " 'total_loss': 0.8745973706245422}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKZyP9A1dxit"
      },
      "source": [
        "The lower the RMSE metric, the more accurate our model is at predicting ratings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efApI0Ii6srB"
      },
      "source": [
        "## Next steps\n",
        "\n",
        "The model above gives us a decent start towards building a ranking system.\n",
        "\n",
        "Of course, making a practical ranking system requires much more effort.\n",
        "\n",
        "In most cases, a ranking model can be substantially improved by using more features rather than just user and candidate identifiers. To see how to do that, have a look at the [side features](featurization) tutorial.\n",
        "\n",
        "A careful understanding of the objectives worth optimizing is also necessary. To get started on building a recommender that optimizes multiple objectives, have a look at our [multitask](multitask) tutorial."
      ]
    }
  ]
}