{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf2_keras_lenet_mnist.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/n-n-n/notebooks/blob/main/orca/quickstart/tf2_keras_lenet_mnist_dataframe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgV_QLGE9Lox"
      },
      "source": [
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDBPZ0_rfBmU"
      },
      "source": [
        "##### Copyright 2018 Analytics Zoo Authors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBWVU_bhfkY7"
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "#"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voMBntim9bMf"
      },
      "source": [
        "## **Environment Preparation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccXnsv_pMCHQ"
      },
      "source": [
        "**Install Java 8**\n",
        "\n",
        "Run the cell on the **Google Colab** to install jdk 1.8.\n",
        "\n",
        "**Note:** if you run this notebook on your computer, root permission is required when running the cell to install Java 8. (You may ignore this cell if Java 8 has already been set up in your computer).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWx_0DSnXVhz",
        "outputId": "fe369a12-6350-42ac-faf7-6890c9bf34e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Install jdk8\n",
        "! apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "import os\n",
        "# Set environment variable JAVA_HOME.\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "! update-alternatives --set java /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\n",
        "! java -version"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java to provide /usr/bin/java (java) in manual mode\n",
            "openjdk version \"1.8.0_292\"\n",
            "OpenJDK Runtime Environment (build 1.8.0_292-8u292-b10-0ubuntu1~18.04-b10)\n",
            "OpenJDK 64-Bit Server VM (build 25.292-b10, mixed mode)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_OS4HKJMNpv"
      },
      "source": [
        "**Install Analytics Zoo**\n",
        "\n",
        "You can install the latest pre-release version using `pip install --pre --upgrade analytics-zoo`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qfT8CaC51hI",
        "outputId": "fe1a4501-da24-424a-fcff-4bd0e2b21f3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Install latest pre-release version of Analytics Zoo \n",
        "# Installing Analytics Zoo from pip will automatically install pyspark, bigdl, and their dependencies.\n",
        "!pip install --pre --upgrade analytics-zoo[ray]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting analytics-zoo[ray]\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4a/73/ebf6ea567f666fb920471ba4cb29c1253fad7c423186c8f03c88ebf1342d/analytics_zoo-0.11.0b20210630-py2.py3-none-manylinux1_x86_64.whl (205.0MB)\n",
            "\u001b[K     |████████████████████████████████| 205.0MB 58kB/s \n",
            "\u001b[?25hCollecting conda-pack==0.3.1\n",
            "  Downloading https://files.pythonhosted.org/packages/e9/e7/d942780c4281a665f34dbfffc1cd1517c5843fb478c133a1e1fa0df30cd6/conda_pack-0.3.1-py2.py3-none-any.whl\n",
            "Collecting bigdl==0.12.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/40/81fed203a633536dbb83454f1a102ebde86214f576572769290afb9427c9/BigDL-0.12.2-py2.py3-none-manylinux1_x86_64.whl (114.1MB)\n",
            "\u001b[K     |████████████████████████████████| 114.1MB 28kB/s \n",
            "\u001b[?25hCollecting pyspark==2.4.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/37/98/244399c0daa7894cdf387e7007d5e8b3710a79b67f3fd991c0b0b644822d/pyspark-2.4.3.tar.gz (215.6MB)\n",
            "\u001b[K     |████████████████████████████████| 215.6MB 68kB/s \n",
            "\u001b[?25hCollecting aiohttp==3.7.0; extra == \"ray\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/84/44/3722592d693a037a0ebb4106c7645c77dd06b062ed8ab2e2bf150580967a/aiohttp-3.7.0-cp37-cp37m-manylinux2014_x86_64.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 24.9MB/s \n",
            "\u001b[?25hCollecting setproctitle; extra == \"ray\"\n",
            "  Downloading https://files.pythonhosted.org/packages/97/5c/16a6e69febfbee3f1a1a8c4318d1f054ff4d3ef2a61b233937c316cba06d/setproctitle-1.2.2-cp37-cp37m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied, skipping upgrade: psutil; extra == \"ray\" in /usr/local/lib/python3.7/dist-packages (from analytics-zoo[ray]) (5.4.8)\n",
            "Collecting hiredis==1.1.0; extra == \"ray\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/09/986288478cd05126c7f8eeec912d051b8e4fa52965d5c26d066d6dbce194/hiredis-1.1.0-cp37-cp37m-manylinux2010_x86_64.whl (62kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 8.4MB/s \n",
            "\u001b[?25hCollecting aioredis==1.1.0; extra == \"ray\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/83/4f/fb41fd054522b2f15cf8c9a0b119096a3f2e4db41c9cd7c114da8de742b1/aioredis-1.1.0-py3-none-any.whl (65kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 8.4MB/s \n",
            "\u001b[?25hCollecting ray==1.2.0; extra == \"ray\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/11/14/15d0f0aec20a4674a996429160565a071688f27f49f789327ebed8188ffb/ray-1.2.0-cp37-cp37m-manylinux2014_x86_64.whl (47.5MB)\n",
            "\u001b[K     |████████████████████████████████| 47.5MB 136kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from conda-pack==0.3.1->analytics-zoo[ray]) (57.0.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from bigdl==0.12.2->analytics-zoo[ray]) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from bigdl==0.12.2->analytics-zoo[ray]) (1.19.5)\n",
            "Collecting py4j==0.10.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl (197kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 45.8MB/s \n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f1/62/046834c5fc998c88ab2ef722f5d42122230a632212c8afa76418324f53ff/yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294kB)\n",
            "\u001b[K     |████████████████████████████████| 296kB 46.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: chardet<4.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.7.0; extra == \"ray\"->analytics-zoo[ray]) (3.0.4)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/a6/4123b8165acbe773d1a8dc8e3f0d1edea16d29f7de018eda769abb56bd30/multidict-5.1.0-cp37-cp37m-manylinux2014_x86_64.whl (142kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 40.9MB/s \n",
            "\u001b[?25hCollecting async-timeout<4.0,>=3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e1/1e/5a4441be21b0726c4464f3f23c8b19628372f606755a9d2e46c187e65ec4/async_timeout-3.0.1-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.7.0; extra == \"ray\"->analytics-zoo[ray]) (21.2.0)\n",
            "Collecting aiohttp-cors\n",
            "  Downloading https://files.pythonhosted.org/packages/13/e7/e436a0c0eb5127d8b491a9b83ecd2391c6ff7dcd5548dfaec2080a2340fd/aiohttp_cors-0.7.0-py3-none-any.whl\n",
            "Collecting py-spy>=0.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/19/508f97270d9d57d46797303e09bceeeea7c850451d528ac4cf0bdc680848/py_spy-0.4.0.dev1-py2.py3-none-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 38.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/dist-packages (from ray==1.2.0; extra == \"ray\"->analytics-zoo[ray]) (2.23.0)\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Collecting gpustat\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/09/93/53c9a9b688fc5f87ee1b2c0ad0ca4e56108b0ae31f1327e671a3f42b9eba/gpustat-1.0.0b1.tar.gz (82kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 10.5MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray==1.2.0; extra == \"ray\"->analytics-zoo[ray]) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray==1.2.0; extra == \"ray\"->analytics-zoo[ray]) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: prometheus-client>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from ray==1.2.0; extra == \"ray\"->analytics-zoo[ray]) (0.11.0)\n",
            "Requirement already satisfied, skipping upgrade: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray==1.2.0; extra == \"ray\"->analytics-zoo[ray]) (2.6.0)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.28.1 in /usr/local/lib/python3.7/dist-packages (from ray==1.2.0; extra == \"ray\"->analytics-zoo[ray]) (1.34.1)\n",
            "Collecting redis>=3.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a7/7c/24fb0511df653cf1a5d938d8f5d19802a88cef255706fdda242ff97e91b7/redis-3.5.3-py2.py3-none-any.whl (72kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 9.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.7/dist-packages (from ray==1.2.0; extra == \"ray\"->analytics-zoo[ray]) (3.0.12)\n",
            "Collecting opencensus\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/59/12044123133d000f705383ad98579aeb0dd82d66b33a254a21b54bf0d6bb/opencensus-0.7.13-py2.py3-none-any.whl (127kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 45.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from ray==1.2.0; extra == \"ray\"->analytics-zoo[ray]) (3.12.4)\n",
            "Requirement already satisfied, skipping upgrade: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray==1.2.0; extra == \"ray\"->analytics-zoo[ray]) (1.0.2)\n",
            "Collecting colorful\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4e/47/c0838017b456191529eb890aab5fc48538435d81e19c38badfa762dcfd1d/colorful-0.6.0a1-py2.py3-none-any.whl (202kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 45.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: typing-extensions>=3.7.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from yarl<2.0,>=1.0->aiohttp==3.7.0; extra == \"ray\"->analytics-zoo[ray]) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: idna>=2.0 in /usr/local/lib/python3.7/dist-packages (from yarl<2.0,>=1.0->aiohttp==3.7.0; extra == \"ray\"->analytics-zoo[ray]) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ray==1.2.0; extra == \"ray\"->analytics-zoo[ray]) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ray==1.2.0; extra == \"ray\"->analytics-zoo[ray]) (2021.5.30)\n",
            "Requirement already satisfied, skipping upgrade: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.7/dist-packages (from gpustat->ray==1.2.0; extra == \"ray\"->analytics-zoo[ray]) (7.352.0)\n",
            "Collecting blessed>=1.17.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/7b/5ae28215407a11f8f935cc8d4e5e67cb473e8a5154c6275f153e3a480357/blessed-1.18.1-py2.py3-none-any.whl (56kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 6.7MB/s \n",
            "\u001b[?25hCollecting opencensus-context==0.1.2\n",
            "  Downloading https://files.pythonhosted.org/packages/f1/33/990f1bd9e7ee770fc8d3c154fc24743a96f16a0e49e14e1b7540cc2fdd93/opencensus_context-0.1.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: google-api-core<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from opencensus->ray==1.2.0; extra == \"ray\"->analytics-zoo[ray]) (1.26.3)\n",
            "Requirement already satisfied, skipping upgrade: wcwidth>=0.1.4 in /usr/local/lib/python3.7/dist-packages (from blessed>=1.17.1->gpustat->ray==1.2.0; extra == \"ray\"->analytics-zoo[ray]) (0.2.5)\n",
            "Requirement already satisfied, skipping upgrade: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray==1.2.0; extra == \"ray\"->analytics-zoo[ray]) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray==1.2.0; extra == \"ray\"->analytics-zoo[ray]) (20.9)\n",
            "Requirement already satisfied, skipping upgrade: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray==1.2.0; extra == \"ray\"->analytics-zoo[ray]) (1.53.0)\n",
            "Requirement already satisfied, skipping upgrade: google-auth<2.0dev,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray==1.2.0; extra == \"ray\"->analytics-zoo[ray]) (1.31.0)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2.0.0,>=1.0.0->opencensus->ray==1.2.0; extra == \"ray\"->analytics-zoo[ray]) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray==1.2.0; extra == \"ray\"->analytics-zoo[ray]) (0.2.8)\n",
            "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray==1.2.0; extra == \"ray\"->analytics-zoo[ray]) (4.7.2)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray==1.2.0; extra == \"ray\"->analytics-zoo[ray]) (4.2.2)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray==1.2.0; extra == \"ray\"->analytics-zoo[ray]) (0.4.8)\n",
            "Building wheels for collected packages: pyspark, gpustat\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-2.4.3-py2.py3-none-any.whl size=215964968 sha256=0b63bcb3f8dad53ad549476df476501a7f5e7e58a94bf0d8530075eef90312db\n",
            "  Stored in directory: /root/.cache/pip/wheels/8d/20/f0/b30e2024226dc112e256930dd2cd4f06d00ab053c86278dcf3\n",
            "  Building wheel for gpustat (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gpustat: filename=gpustat-1.0.0b1-cp37-none-any.whl size=15980 sha256=31e8ad0dc5782ac3422a015b5fb395714417f3e2ecacfa0bcf94902218d305cd\n",
            "  Stored in directory: /root/.cache/pip/wheels/b7/ce/db/3d3ee9515083c2e7e313aa34a01a1bd1ad6bcaae61f6852e9b\n",
            "Successfully built pyspark gpustat\n",
            "Installing collected packages: conda-pack, py4j, pyspark, bigdl, multidict, yarl, async-timeout, aiohttp, setproctitle, hiredis, aioredis, aiohttp-cors, py-spy, colorama, blessed, gpustat, redis, opencensus-context, opencensus, colorful, ray, analytics-zoo\n",
            "Successfully installed aiohttp-3.7.0 aiohttp-cors-0.7.0 aioredis-1.1.0 analytics-zoo-0.11.0b20210630 async-timeout-3.0.1 bigdl-0.12.2 blessed-1.18.1 colorama-0.4.4 colorful-0.6.0a1 conda-pack-0.3.1 gpustat-1.0.0b1 hiredis-1.1.0 multidict-5.1.0 opencensus-0.7.13 opencensus-context-0.1.2 py-spy-0.4.0.dev1 py4j-0.10.7 pyspark-2.4.3 ray-1.2.0 redis-3.5.3 setproctitle-1.2.2 yarl-1.6.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-l4vel5N3qP"
      },
      "source": [
        "## **Distributed TensorFlow 2 using Orca APIs**\n",
        "\n",
        "In this guide we will describe how to scale out TensorFlow 2 programs using Orca in 4 simple steps."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDPt2XTsT-Gv",
        "outputId": "903dd15e-bdfe-446c-a091-b4bece3a0fe2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# import necesary libraries and modules\n",
        "import argparse\n",
        "\n",
        "from zoo.orca import init_orca_context, stop_orca_context\n",
        "from zoo.orca import OrcaContext"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prepending /usr/local/lib/python3.7/dist-packages/bigdl/share/conf/spark-bigdl.conf to sys.path\n",
            "Adding /usr/local/lib/python3.7/dist-packages/zoo/share/lib/analytics-zoo-bigdl_0.12.2-spark_2.4.3-0.11.0-SNAPSHOT-jar-with-dependencies.jar to BIGDL_JARS\n",
            "Prepending /usr/local/lib/python3.7/dist-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBdeoZzLWWlY"
      },
      "source": [
        "### **Step 1: Init Orca Context** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAQp0FcUWaH3",
        "outputId": "d5872413-77b9-4645-fb4b-0f1a0915794a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# recommended to set it to True when running Analytics Zoo in Jupyter notebook \n",
        "OrcaContext.log_output = True # (this will display terminal's stdout and stderr in the Jupyter notebook).\n",
        "\n",
        "cluster_mode = \"local\"\n",
        "\n",
        "if cluster_mode == \"local\":  \n",
        "    init_orca_context(cluster_mode=\"local\", cores=4) # run in local mode\n",
        "elif cluster_mode == \"k8s\":  \n",
        "    init_orca_context(cluster_mode=\"k8s\", num_nodes=2, cores=2) # run on K8s cluster\n",
        "elif cluster_mode == \"yarn\":  \n",
        "    init_orca_context(cluster_mode=\"yarn-client\", num_nodes=2, cores=2) # run on Hadoop YARN cluster"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initializing orca context\n",
            "Current pyspark location is : /usr/local/lib/python3.7/dist-packages/pyspark/__init__.py\n",
            "Start to getOrCreate SparkContext\n",
            "pyspark_submit_args is:  --driver-class-path /usr/local/lib/python3.7/dist-packages/zoo/share/lib/analytics-zoo-bigdl_0.12.2-spark_2.4.3-0.11.0-SNAPSHOT-jar-with-dependencies.jar:/usr/local/lib/python3.7/dist-packages/bigdl/share/lib/bigdl-0.12.2-jar-with-dependencies.jar pyspark-shell \n",
            "2021-07-01 01:24:48 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "SLF4J: Class path contains multiple SLF4J bindings.\n",
            "SLF4J: Found binding in [jar:file:/usr/local/lib/python3.7/dist-packages/zoo/share/lib/analytics-zoo-bigdl_0.12.2-spark_2.4.3-0.11.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
            "SLF4J: Found binding in [jar:file:/usr/local/lib/python3.7/dist-packages/pyspark/jars/slf4j-log4j12-1.7.16.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
            "SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\n",
            "SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]\n",
            "Setting default log level to \"WARN\".\n",
            "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "cls.getname: com.intel.analytics.bigdl.python.api.Sample\n",
            "BigDLBasePickler registering: bigdl.util.common  Sample\n",
            "cls.getname: com.intel.analytics.bigdl.python.api.EvaluatedResult\n",
            "BigDLBasePickler registering: bigdl.util.common  EvaluatedResult\n",
            "cls.getname: com.intel.analytics.bigdl.python.api.JTensor\n",
            "BigDLBasePickler registering: bigdl.util.common  JTensor\n",
            "cls.getname: com.intel.analytics.bigdl.python.api.JActivitySuccessfully got a SparkContext\n",
            "\n",
            "BigDLBasePickler registering: bigdl.util.common  JActivity\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "User settings:\n",
            "\n",
            "   KMP_AFFINITY=granularity=fine,compact,1,0\n",
            "   KMP_BLOCKTIME=0\n",
            "   KMP_SETTINGS=1\n",
            "   OMP_NUM_THREADS=1\n",
            "\n",
            "Effective settings:\n",
            "\n",
            "   KMP_ABORT_DELAY=0\n",
            "   KMP_ADAPTIVE_LOCK_PROPS='1,1024'\n",
            "   KMP_ALIGN_ALLOC=64\n",
            "   KMP_ALL_THREADPRIVATE=128\n",
            "   KMP_ATOMIC_MODE=2\n",
            "   KMP_BLOCKTIME=0\n",
            "   KMP_CPUINFO_FILE: value is not defined\n",
            "   KMP_DETERMINISTIC_REDUCTION=false\n",
            "   KMP_DEVICE_THREAD_LIMIT=2147483647\n",
            "   KMP_DISP_HAND_THREAD=false\n",
            "   KMP_DISP_NUM_BUFFERS=7\n",
            "   KMP_DUPLICATE_LIB_OK=false\n",
            "   KMP_FORCE_REDUCTION: value is not defined\n",
            "   KMP_FOREIGN_THREADS_THREADPRIVATE=true\n",
            "   KMP_FORKJOIN_BARRIER='2,2'\n",
            "   KMP_FORKJOIN_BARRIER_PATTERN='hyper,hyper'\n",
            "   KMP_FORKJOIN_FRAMES=true\n",
            "   KMP_FORKJOIN_FRAMES_MODE=3\n",
            "   KMP_GTID_MODE=3\n",
            "   KMP_HANDLE_SIGNALS=false\n",
            "   KMP_HOT_TEAMS_MAX_LEVEL=1\n",
            "   KMP_HOT_TEAMS_MODE=0\n",
            "   KMP_INIT_AT_FORK=true\n",
            "   KMP_ITT_PREPARE_DELAY=0\n",
            "   KMP_LIBRARY=throughput\n",
            "   KMP_LOCK_KIND=queuing\n",
            "   KMP_MALLOC_POOL_INCR=1M\n",
            "   KMP_MWAIT_HINTS=0\n",
            "   KMP_NUM_LOCKS_IN_BLOCK=1\n",
            "   KMP_PLAIN_BARRIER='2,2'\n",
            "   KMP_PLAIN_BARRIER_PATTERN='hyper,hyper'\n",
            "   KMP_REDUCTION_BARRIER='1,1'\n",
            "   KMP_REDUCTION_BARRIER_PATTERN='hyper,hyper'\n",
            "   KMP_SCHEDULE='static,balanced;guided,iterative'\n",
            "   KMP_SETTINGS=true\n",
            "   KMP_SPIN_BACKOFF_PARAMS='4096,100'\n",
            "   KMP_STACKOFFSET=64\n",
            "   KMP_STACKPAD=0\n",
            "   KMP_STACKSIZE=8M\n",
            "   KMP_STORAGE_MAP=false\n",
            "   KMP_TASKING=2\n",
            "   KMP_TASKLOOP_MIN_TASKS=0\n",
            "   KMP_TASK_STEALING_CONSTRAINT=1\n",
            "   KMP_TEAMS_THREAD_LIMIT=2\n",
            "   KMP_TOPOLOGY_METHOD=all\n",
            "   KMP_USER_LEVEL_MWAIT=false\n",
            "   KMP_USE_YIELD=1\n",
            "   KMP_VERSION=false\n",
            "   KMP_WARNINGS=true\n",
            "   OMP_AFFINITY_FORMAT='OMP: pid %P tid %i thread %n bound to OS proc set {%A}'\n",
            "   OMP_ALLOCATOR=omp_default_mem_alloc\n",
            "   OMP_CANCELLATION=false\n",
            "   OMP_DEBUG=disabled\n",
            "   OMP_DEFAULT_DEVICE=0\n",
            "   OMP_DISPLAY_AFFINITY=false\n",
            "   OMP_DISPLAY_ENV=false\n",
            "   OMP_DYNAMIC=false\n",
            "   OMP_MAX_ACTIVE_LEVELS=2147483647\n",
            "   OMP_MAX_TASK_PRIORITY=0\n",
            "   OMP_NESTED=false\n",
            "   OMP_NUM_THREADS='1'\n",
            "   OMP_PLACES: value is not defined\n",
            "   OMP_PROC_BIND='intel'\n",
            "   OMP_SCHEDULE='static'\n",
            "   OMP_STACKSIZE=8M\n",
            "   OMP_TARGET_OFFLOAD=DEFAULT\n",
            "   OMP_THREAD_LIMIT=2147483647\n",
            "   OMP_TOOL=enabled\n",
            "   OMP_TOOL_LIBRARIES: value is not defined\n",
            "   OMP_WAIT_POLICY=PASSIVE\n",
            "   KMP_AFFINITY='noverbose,warnings,respect,granularity=fine,compact,1,0'\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VyfhD6HVQpm"
      },
      "source": [
        "This is the only place where you need to specify local or distributed mode. View [Orca Context](https://analytics-zoo.readthedocs.io/en/latest/doc/Orca/Overview/orca-context.html) for more details.\n",
        "\n",
        "**Note**: You should export HADOOP_CONF_DIR=/path/to/hadoop/conf/dir when you run on Hadoop YARN cluster."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ld-pV8e-Vb7D"
      },
      "source": [
        "### **Step 2: Define the Model**\n",
        "\n",
        "You can then define the Keras model in the *Creator Function* using the standard TensroFlow 2 APIs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DC1P7_gP9FKm"
      },
      "source": [
        "def model_creator(config):\n",
        "    import tensorflow as tf\n",
        "    model = tf.keras.Sequential(\n",
        "        [tf.keras.layers.Conv2D(20, kernel_size=(5, 5), strides=(1, 1), activation='tanh',\n",
        "                                input_shape=(28, 28, 1), padding='valid'),\n",
        "         tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'),\n",
        "         tf.keras.layers.Conv2D(50, kernel_size=(5, 5), strides=(1, 1), activation='tanh',\n",
        "                                padding='valid'),\n",
        "         tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'),\n",
        "         tf.keras.layers.Flatten(),\n",
        "         tf.keras.layers.Dense(500, activation='tanh'),\n",
        "         tf.keras.layers.Dense(10, activation='softmax'),\n",
        "         ]\n",
        "    )\n",
        "\n",
        "    model.compile(optimizer=tf.keras.optimizers.RMSprop(),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiTnHATGYn_f"
      },
      "source": [
        "### **Step 3: Define Train Dataset**\n",
        "\n",
        "You can define the dataset in the _Creator Function_ using standard [tf.data.Dataset](https://www.tensorflow.org/api_docs/python/tf/data/Dataset) APIs. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YHW93myYykE"
      },
      "source": [
        "def preprocess(x, y):\n",
        "    import tensorflow as tf\n",
        "    x = tf.cast(tf.reshape(x, (28, 28, 1)), dtype=tf.float32) / 255.0\n",
        "    return x, y\n",
        "\n",
        "def train_data_creator(config, batch_size):\n",
        "    import tensorflow as tf\n",
        "    (train_feature, train_label), _ = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((train_feature, train_label))\n",
        "    dataset = dataset.repeat()\n",
        "    dataset = dataset.map(preprocess)\n",
        "    dataset = dataset.shuffle(1000)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    return dataset\n",
        "\n",
        "def val_data_creator(config, batch_size):\n",
        "    import tensorflow as tf\n",
        "    _, (val_feature, val_label) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((val_feature, val_label))\n",
        "    dataset = dataset.repeat()\n",
        "    dataset = dataset.map(preprocess)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    return dataset"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnbOmWHsXOmg"
      },
      "source": [
        "### **Step 4: Fit with Orca Estimator**\n",
        "\n",
        "First, create an Estimator.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsNbQROFXNgU",
        "outputId": "f5ea7817-4302-48f9-b6a5-3dcf844c9906",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from zoo.orca.learn.tf2 import Estimator\n",
        "\n",
        "batch_size = 320\n",
        "est = Estimator.from_keras(model_creator=model_creator, workers_per_node=1)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-07-01 01:24:54,298\tINFO services.py:1174 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://172.28.0.2:8265\u001b[39m\u001b[22m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'node_ip_address': '172.28.0.2', 'raylet_ip_address': '172.28.0.2', 'redis_address': '172.28.0.2:6379', 'object_store_address': '/tmp/ray/session_2021-07-01_01-24-53_602579_61/sockets/plasma_store', 'raylet_socket_name': '/tmp/ray/session_2021-07-01_01-24-53_602579_61/sockets/raylet', 'webui_url': '172.28.0.2:8265', 'session_dir': '/tmp/ray/session_2021-07-01_01-24-53_602579_61', 'metrics_export_port': 54321, 'node_id': 'cd4a1f92027bd5a3efc4beb658b2712e4845f5bf31e2c3e5263d1cdc'}\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m Prepending /usr/local/lib/python3.7/dist-packages/bigdl/share/conf/spark-bigdl.conf to sys.path\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m Prepending /usr/local/lib/python3.7/dist-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m 2021-07-01 01:24:58.098085: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/zoo/orca/learn/tf2/tf_runner.py:314: _CollectiveAllReduceStrategyExperimental.__init__ (from tensorflow.python.distribute.collective_all_reduce_strategy) is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m use distribute.MultiWorkerMirroredStrategy instead\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m 2021-07-01 01:24:59.607743: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m 2021-07-01 01:24:59.726310: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m 2021-07-01 01:24:59.726391: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (0446f383d63b): /proc/driver/nvidia/version does not exist\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m 2021-07-01 01:24:59.801281: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 172.28.0.2:43599}\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m 2021-07-01 01:24:59.801671: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:411] Started server with target: grpc://172.28.0.2:43599\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bNtls5WXnzU"
      },
      "source": [
        "Next, fit the Estimator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imhbbDNXXsXR",
        "outputId": "fe34e959-faa5-43ee-fc20-9ab9b5eec633",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "max_epoch=1\n",
        "stats = est.fit(train_data_creator,\n",
        "                epochs=max_epoch,\n",
        "                batch_size=batch_size,\n",
        "                steps_per_epoch=60000 // batch_size,\n",
        "                validation_data=val_data_creator,\n",
        "                validation_steps=10000 // batch_size)\n",
        "est.save(\"/tmp/mnist_keras.ckpt\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m \r    8192/11490434 [..............................] - ETA: 0s\n",
            " 7077888/11490434 [=================>............] - ETA: 0s\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function preprocess at 0x7fb72271e680> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m Cause: Unable to locate the source code of <function preprocess at 0x7fb72271e680>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function preprocess at 0x7fb722828d40> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m Cause: Unable to locate the source code of <function preprocess at 0x7fb722828d40>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m 2021-07-01 01:25:01.382645: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m op: \"TensorSliceDataset\"\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m input: \"Placeholder/_0\"\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m input: \"Placeholder/_1\"\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m attr {\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m   key: \"Toutput_types\"\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m   value {\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m     list {\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m       type: DT_UINT8\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m       type: DT_UINT8\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m     }\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m   }\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m }\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m attr {\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m   key: \"output_shapes\"\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m   value {\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m     list {\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m       shape {\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m         dim {\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m           size: 28\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m         }\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m         dim {\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m           size: 28\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m         }\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m       }\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m       shape {\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m       }\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m     }\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m   }\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m }\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m \n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m 2021-07-01 01:25:01.460473: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m 2021-07-01 01:25:01.460945: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2199995000 Hz\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  1/187 [..............................] - ETA: 10:09 - loss: 2.2997 - accuracy: 0.0719\n",
            "  2/187 [..............................] - ETA: 48s - loss: 2.3565 - accuracy: 0.1375  \n",
            "  3/187 [..............................] - ETA: 47s - loss: 2.1103 - accuracy: 0.2885\n",
            "  4/187 [..............................] - ETA: 46s - loss: 1.8937 - accuracy: 0.3812\n",
            "  5/187 [..............................] - ETA: 45s - loss: 1.7138 - accuracy: 0.4619\n",
            "  6/187 [..............................] - ETA: 45s - loss: 1.5586 - accuracy: 0.5141\n",
            "  7/187 [>.............................] - ETA: 45s - loss: 1.4303 - accuracy: 0.5661\n",
            "  8/187 [>.............................] - ETA: 45s - loss: 1.3211 - accuracy: 0.6031\n",
            "  9/187 [>.............................] - ETA: 44s - loss: 1.2356 - accuracy: 0.6302\n",
            " 10/187 [>.............................] - ETA: 44s - loss: 1.1617 - accuracy: 0.6553\n",
            " 11/187 [>.............................] - ETA: 44s - loss: 1.0969 - accuracy: 0.6741\n",
            " 12/187 [>.............................] - ETA: 43s - loss: 1.0501 - accuracy: 0.6875\n",
            " 13/187 [=>............................] - ETA: 43s - loss: 1.0132 - accuracy: 0.6969\n",
            " 14/187 [=>............................] - ETA: 43s - loss: 0.9775 - accuracy: 0.7069\n",
            " 15/187 [=>............................] - ETA: 43s - loss: 0.9464 - accuracy: 0.7160\n",
            " 16/187 [=>............................] - ETA: 42s - loss: 0.9149 - accuracy: 0.7250\n",
            " 17/187 [=>............................] - ETA: 42s - loss: 0.8827 - accuracy: 0.7355\n",
            " 18/187 [=>............................] - ETA: 42s - loss: 0.8489 - accuracy: 0.7457\n",
            " 19/187 [==>...........................] - ETA: 42s - loss: 0.8188 - accuracy: 0.7551\n",
            " 20/187 [==>...........................] - ETA: 41s - loss: 0.7957 - accuracy: 0.7617\n",
            " 21/187 [==>...........................] - ETA: 41s - loss: 0.7762 - accuracy: 0.7682\n",
            " 22/187 [==>...........................] - ETA: 41s - loss: 0.7550 - accuracy: 0.7750\n",
            " 23/187 [==>...........................] - ETA: 41s - loss: 0.7340 - accuracy: 0.7817\n",
            " 24/187 [==>...........................] - ETA: 41s - loss: 0.7175 - accuracy: 0.7857\n",
            " 25/187 [===>..........................] - ETA: 40s - loss: 0.7034 - accuracy: 0.7899\n",
            " 26/187 [===>..........................] - ETA: 40s - loss: 0.6939 - accuracy: 0.7923\n",
            " 27/187 [===>..........................] - ETA: 40s - loss: 0.6842 - accuracy: 0.7954\n",
            " 28/187 [===>..........................] - ETA: 40s - loss: 0.6746 - accuracy: 0.7979\n",
            " 29/187 [===>..........................] - ETA: 40s - loss: 0.6634 - accuracy: 0.8008\n",
            " 30/187 [===>..........................] - ETA: 39s - loss: 0.6476 - accuracy: 0.8056\n",
            " 31/187 [===>..........................] - ETA: 39s - loss: 0.6360 - accuracy: 0.8088\n",
            " 32/187 [====>.........................] - ETA: 39s - loss: 0.6238 - accuracy: 0.8125\n",
            " 33/187 [====>.........................] - ETA: 39s - loss: 0.6135 - accuracy: 0.8152\n",
            " 34/187 [====>.........................] - ETA: 38s - loss: 0.6032 - accuracy: 0.8183\n",
            " 35/187 [====>.........................] - ETA: 38s - loss: 0.5927 - accuracy: 0.8216\n",
            " 36/187 [====>.........................] - ETA: 38s - loss: 0.5845 - accuracy: 0.8246\n",
            " 37/187 [====>.........................] - ETA: 38s - loss: 0.5766 - accuracy: 0.8272\n",
            " 38/187 [=====>........................] - ETA: 37s - loss: 0.5682 - accuracy: 0.8296\n",
            " 39/187 [=====>........................] - ETA: 37s - loss: 0.5637 - accuracy: 0.8310\n",
            " 40/187 [=====>........................] - ETA: 37s - loss: 0.5618 - accuracy: 0.8319\n",
            " 41/187 [=====>........................] - ETA: 37s - loss: 0.5545 - accuracy: 0.8345\n",
            " 42/187 [=====>........................] - ETA: 37s - loss: 0.5481 - accuracy: 0.8362\n",
            " 43/187 [=====>........................] - ETA: 36s - loss: 0.5405 - accuracy: 0.8382\n",
            " 44/187 [======>.......................] - ETA: 36s - loss: 0.5354 - accuracy: 0.8399\n",
            " 45/187 [======>.......................] - ETA: 36s - loss: 0.5294 - accuracy: 0.8419\n",
            " 46/187 [======>.......................] - ETA: 35s - loss: 0.5249 - accuracy: 0.8430\n",
            " 47/187 [======>.......................] - ETA: 35s - loss: 0.5204 - accuracy: 0.8447\n",
            " 48/187 [======>.......................] - ETA: 35s - loss: 0.5155 - accuracy: 0.8465\n",
            " 49/187 [======>.......................] - ETA: 35s - loss: 0.5091 - accuracy: 0.8485\n",
            " 50/187 [=======>......................] - ETA: 34s - loss: 0.5046 - accuracy: 0.8497\n",
            " 51/187 [=======>......................] - ETA: 34s - loss: 0.4985 - accuracy: 0.8515\n",
            " 52/187 [=======>......................] - ETA: 34s - loss: 0.4927 - accuracy: 0.8532\n",
            " 53/187 [=======>......................] - ETA: 34s - loss: 0.4877 - accuracy: 0.8546\n",
            " 54/187 [=======>......................] - ETA: 33s - loss: 0.4815 - accuracy: 0.8565\n",
            " 55/187 [=======>......................] - ETA: 33s - loss: 0.4754 - accuracy: 0.8584\n",
            " 56/187 [=======>......................] - ETA: 33s - loss: 0.4702 - accuracy: 0.8598\n",
            " 57/187 [========>.....................] - ETA: 33s - loss: 0.4653 - accuracy: 0.8615\n",
            " 58/187 [========>.....................] - ETA: 32s - loss: 0.4595 - accuracy: 0.8633\n",
            " 59/187 [========>.....................] - ETA: 32s - loss: 0.4539 - accuracy: 0.8650\n",
            " 60/187 [========>.....................] - ETA: 32s - loss: 0.4491 - accuracy: 0.8667\n",
            " 61/187 [========>.....................] - ETA: 32s - loss: 0.4466 - accuracy: 0.8675\n",
            " 62/187 [========>.....................] - ETA: 31s - loss: 0.4408 - accuracy: 0.8693\n",
            " 63/187 [=========>....................] - ETA: 31s - loss: 0.4358 - accuracy: 0.8708\n",
            " 64/187 [=========>....................] - ETA: 31s - loss: 0.4334 - accuracy: 0.8715\n",
            " 65/187 [=========>....................] - ETA: 31s - loss: 0.4315 - accuracy: 0.8720\n",
            " 66/187 [=========>....................] - ETA: 30s - loss: 0.4278 - accuracy: 0.8730\n",
            " 67/187 [=========>....................] - ETA: 30s - loss: 0.4237 - accuracy: 0.8743\n",
            " 68/187 [=========>....................] - ETA: 30s - loss: 0.4192 - accuracy: 0.8757\n",
            " 69/187 [==========>...................] - ETA: 30s - loss: 0.4153 - accuracy: 0.8766\n",
            " 70/187 [==========>...................] - ETA: 29s - loss: 0.4112 - accuracy: 0.8777\n",
            " 71/187 [==========>...................] - ETA: 29s - loss: 0.4074 - accuracy: 0.8788\n",
            " 72/187 [==========>...................] - ETA: 29s - loss: 0.4044 - accuracy: 0.8798\n",
            " 73/187 [==========>...................] - ETA: 29s - loss: 0.4012 - accuracy: 0.8809\n",
            " 74/187 [==========>...................] - ETA: 28s - loss: 0.3980 - accuracy: 0.8817\n",
            " 75/187 [===========>..................] - ETA: 28s - loss: 0.3947 - accuracy: 0.8826\n",
            " 76/187 [===========>..................] - ETA: 28s - loss: 0.3925 - accuracy: 0.8835\n",
            " 77/187 [===========>..................] - ETA: 28s - loss: 0.3894 - accuracy: 0.8843\n",
            " 78/187 [===========>..................] - ETA: 27s - loss: 0.3861 - accuracy: 0.8853\n",
            " 79/187 [===========>..................] - ETA: 27s - loss: 0.3828 - accuracy: 0.8865\n",
            " 80/187 [===========>..................] - ETA: 27s - loss: 0.3796 - accuracy: 0.8874\n",
            " 81/187 [===========>..................] - ETA: 27s - loss: 0.3771 - accuracy: 0.8880\n",
            " 82/187 [============>.................] - ETA: 26s - loss: 0.3745 - accuracy: 0.8888\n",
            " 83/187 [============>.................] - ETA: 26s - loss: 0.3719 - accuracy: 0.8894\n",
            " 84/187 [============>.................] - ETA: 26s - loss: 0.3690 - accuracy: 0.8902\n",
            " 85/187 [============>.................] - ETA: 25s - loss: 0.3663 - accuracy: 0.8911\n",
            " 86/187 [============>.................] - ETA: 25s - loss: 0.3639 - accuracy: 0.8918\n",
            " 87/187 [============>.................] - ETA: 25s - loss: 0.3618 - accuracy: 0.8923\n",
            " 88/187 [=============>................] - ETA: 25s - loss: 0.3594 - accuracy: 0.8930\n",
            " 89/187 [=============>................] - ETA: 24s - loss: 0.3579 - accuracy: 0.8934\n",
            " 90/187 [=============>................] - ETA: 24s - loss: 0.3551 - accuracy: 0.8941\n",
            " 91/187 [=============>................] - ETA: 24s - loss: 0.3527 - accuracy: 0.8948\n",
            " 92/187 [=============>................] - ETA: 24s - loss: 0.3502 - accuracy: 0.8956\n",
            " 93/187 [=============>................] - ETA: 23s - loss: 0.3483 - accuracy: 0.8961\n",
            " 94/187 [==============>...............] - ETA: 23s - loss: 0.3467 - accuracy: 0.8965\n",
            " 95/187 [==============>...............] - ETA: 23s - loss: 0.3458 - accuracy: 0.8968\n",
            " 96/187 [==============>...............] - ETA: 23s - loss: 0.3434 - accuracy: 0.8975\n",
            " 97/187 [==============>...............] - ETA: 22s - loss: 0.3410 - accuracy: 0.8982\n",
            " 98/187 [==============>...............] - ETA: 22s - loss: 0.3388 - accuracy: 0.8989\n",
            " 99/187 [==============>...............] - ETA: 22s - loss: 0.3371 - accuracy: 0.8993\n",
            "100/187 [===============>..............] - ETA: 22s - loss: 0.3345 - accuracy: 0.9001\n",
            "101/187 [===============>..............] - ETA: 21s - loss: 0.3334 - accuracy: 0.9005\n",
            "102/187 [===============>..............] - ETA: 21s - loss: 0.3314 - accuracy: 0.9011\n",
            "103/187 [===============>..............] - ETA: 21s - loss: 0.3295 - accuracy: 0.9017\n",
            "104/187 [===============>..............] - ETA: 21s - loss: 0.3269 - accuracy: 0.9024\n",
            "105/187 [===============>..............] - ETA: 20s - loss: 0.3248 - accuracy: 0.9030\n",
            "106/187 [================>.............] - ETA: 20s - loss: 0.3231 - accuracy: 0.9036\n",
            "107/187 [================>.............] - ETA: 20s - loss: 0.3215 - accuracy: 0.9040\n",
            "108/187 [================>.............] - ETA: 20s - loss: 0.3196 - accuracy: 0.9046\n",
            "109/187 [================>.............] - ETA: 19s - loss: 0.3179 - accuracy: 0.9052\n",
            "110/187 [================>.............] - ETA: 19s - loss: 0.3161 - accuracy: 0.9057\n",
            "111/187 [================>.............] - ETA: 19s - loss: 0.3148 - accuracy: 0.9059\n",
            "112/187 [================>.............] - ETA: 19s - loss: 0.3131 - accuracy: 0.9065\n",
            "113/187 [=================>............] - ETA: 18s - loss: 0.3114 - accuracy: 0.9069\n",
            "114/187 [=================>............] - ETA: 18s - loss: 0.3101 - accuracy: 0.9073\n",
            "115/187 [=================>............] - ETA: 18s - loss: 0.3089 - accuracy: 0.9076\n",
            "116/187 [=================>............] - ETA: 18s - loss: 0.3069 - accuracy: 0.9082\n",
            "117/187 [=================>............] - ETA: 17s - loss: 0.3048 - accuracy: 0.9088\n",
            "118/187 [=================>............] - ETA: 17s - loss: 0.3027 - accuracy: 0.9094\n",
            "119/187 [==================>...........] - ETA: 17s - loss: 0.3011 - accuracy: 0.9099\n",
            "120/187 [==================>...........] - ETA: 17s - loss: 0.2997 - accuracy: 0.9103\n",
            "121/187 [==================>...........] - ETA: 16s - loss: 0.2982 - accuracy: 0.9107\n",
            "122/187 [==================>...........] - ETA: 16s - loss: 0.2972 - accuracy: 0.9110\n",
            "123/187 [==================>...........] - ETA: 16s - loss: 0.2958 - accuracy: 0.9115\n",
            "124/187 [==================>...........] - ETA: 16s - loss: 0.2941 - accuracy: 0.9120\n",
            "125/187 [===================>..........] - ETA: 15s - loss: 0.2927 - accuracy: 0.9124\n",
            "126/187 [===================>..........] - ETA: 15s - loss: 0.2918 - accuracy: 0.9127\n",
            "127/187 [===================>..........] - ETA: 15s - loss: 0.2903 - accuracy: 0.9131\n",
            "128/187 [===================>..........] - ETA: 15s - loss: 0.2893 - accuracy: 0.9135\n",
            "129/187 [===================>..........] - ETA: 14s - loss: 0.2880 - accuracy: 0.9138\n",
            "130/187 [===================>..........] - ETA: 14s - loss: 0.2864 - accuracy: 0.9144\n",
            "131/187 [====================>.........] - ETA: 14s - loss: 0.2850 - accuracy: 0.9147\n",
            "132/187 [====================>.........] - ETA: 14s - loss: 0.2837 - accuracy: 0.9151\n",
            "133/187 [====================>.........] - ETA: 13s - loss: 0.2826 - accuracy: 0.9153\n",
            "134/187 [====================>.........] - ETA: 13s - loss: 0.2813 - accuracy: 0.9157\n",
            "135/187 [====================>.........] - ETA: 13s - loss: 0.2802 - accuracy: 0.9160\n",
            "136/187 [====================>.........] - ETA: 12s - loss: 0.2786 - accuracy: 0.9165\n",
            "137/187 [====================>.........] - ETA: 12s - loss: 0.2772 - accuracy: 0.9170\n",
            "138/187 [=====================>........] - ETA: 12s - loss: 0.2761 - accuracy: 0.9173\n",
            "139/187 [=====================>........] - ETA: 12s - loss: 0.2756 - accuracy: 0.9174\n",
            "140/187 [=====================>........] - ETA: 11s - loss: 0.2749 - accuracy: 0.9175\n",
            "141/187 [=====================>........] - ETA: 11s - loss: 0.2740 - accuracy: 0.9177\n",
            "142/187 [=====================>........] - ETA: 11s - loss: 0.2728 - accuracy: 0.9180\n",
            "143/187 [=====================>........] - ETA: 11s - loss: 0.2717 - accuracy: 0.9184\n",
            "144/187 [======================>.......] - ETA: 10s - loss: 0.2705 - accuracy: 0.9187\n",
            "145/187 [======================>.......] - ETA: 10s - loss: 0.2695 - accuracy: 0.9191\n",
            "146/187 [======================>.......] - ETA: 10s - loss: 0.2685 - accuracy: 0.9194\n",
            "147/187 [======================>.......] - ETA: 10s - loss: 0.2676 - accuracy: 0.9197\n",
            "148/187 [======================>.......] - ETA: 9s - loss: 0.2669 - accuracy: 0.9199 \n",
            "149/187 [======================>.......] - ETA: 9s - loss: 0.2658 - accuracy: 0.9201\n",
            "150/187 [=======================>......] - ETA: 9s - loss: 0.2648 - accuracy: 0.9204\n",
            "151/187 [=======================>......] - ETA: 9s - loss: 0.2636 - accuracy: 0.9207\n",
            "152/187 [=======================>......] - ETA: 8s - loss: 0.2625 - accuracy: 0.9211\n",
            "153/187 [=======================>......] - ETA: 8s - loss: 0.2616 - accuracy: 0.9214\n",
            "154/187 [=======================>......] - ETA: 8s - loss: 0.2609 - accuracy: 0.9215\n",
            "155/187 [=======================>......] - ETA: 8s - loss: 0.2602 - accuracy: 0.9218\n",
            "156/187 [========================>.....] - ETA: 7s - loss: 0.2592 - accuracy: 0.9221\n",
            "157/187 [========================>.....] - ETA: 7s - loss: 0.2580 - accuracy: 0.9224\n",
            "158/187 [========================>.....] - ETA: 7s - loss: 0.2570 - accuracy: 0.9226\n",
            "159/187 [========================>.....] - ETA: 7s - loss: 0.2560 - accuracy: 0.9228\n",
            "160/187 [========================>.....] - ETA: 6s - loss: 0.2551 - accuracy: 0.9231\n",
            "161/187 [========================>.....] - ETA: 6s - loss: 0.2540 - accuracy: 0.9234\n",
            "162/187 [========================>.....] - ETA: 6s - loss: 0.2532 - accuracy: 0.9236\n",
            "163/187 [=========================>....] - ETA: 6s - loss: 0.2521 - accuracy: 0.9239\n",
            "164/187 [=========================>....] - ETA: 5s - loss: 0.2512 - accuracy: 0.9241\n",
            "165/187 [=========================>....] - ETA: 5s - loss: 0.2506 - accuracy: 0.9244\n",
            "166/187 [=========================>....] - ETA: 5s - loss: 0.2498 - accuracy: 0.9247\n",
            "167/187 [=========================>....] - ETA: 5s - loss: 0.2489 - accuracy: 0.9250\n",
            "168/187 [=========================>....] - ETA: 4s - loss: 0.2478 - accuracy: 0.9253\n",
            "169/187 [==========================>...] - ETA: 4s - loss: 0.2469 - accuracy: 0.9256\n",
            "170/187 [==========================>...] - ETA: 4s - loss: 0.2461 - accuracy: 0.9258\n",
            "171/187 [==========================>...] - ETA: 4s - loss: 0.2450 - accuracy: 0.9261\n",
            "172/187 [==========================>...] - ETA: 3s - loss: 0.2442 - accuracy: 0.9263\n",
            "173/187 [==========================>...] - ETA: 3s - loss: 0.2433 - accuracy: 0.9266\n",
            "174/187 [==========================>...] - ETA: 3s - loss: 0.2423 - accuracy: 0.9269\n",
            "175/187 [===========================>..] - ETA: 3s - loss: 0.2415 - accuracy: 0.9271\n",
            "176/187 [===========================>..] - ETA: 2s - loss: 0.2403 - accuracy: 0.9275\n",
            "177/187 [===========================>..] - ETA: 2s - loss: 0.2393 - accuracy: 0.9278\n",
            "178/187 [===========================>..] - ETA: 2s - loss: 0.2383 - accuracy: 0.9281\n",
            "179/187 [===========================>..] - ETA: 2s - loss: 0.2373 - accuracy: 0.9283\n",
            "180/187 [===========================>..] - ETA: 1s - loss: 0.2363 - accuracy: 0.9286\n",
            "181/187 [============================>.] - ETA: 1s - loss: 0.2354 - accuracy: 0.9288\n",
            "182/187 [============================>.] - ETA: 1s - loss: 0.2344 - accuracy: 0.9291\n",
            "183/187 [============================>.] - ETA: 1s - loss: 0.2334 - accuracy: 0.9294\n",
            "184/187 [============================>.] - ETA: 0s - loss: 0.2328 - accuracy: 0.9297\n",
            "185/187 [============================>.] - ETA: 0s - loss: 0.2322 - accuracy: 0.9299\n",
            "186/187 [============================>.] - ETA: 0s - loss: 0.2318 - accuracy: 0.9300\n",
            "187/187 [==============================] - ETA: 0s - loss: 0.2311 - accuracy: 0.9302\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m 2021-07-01 01:25:52.005920: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m op: \"TensorSliceDataset\"\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m input: \"Placeholder/_0\"\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m input: \"Placeholder/_1\"\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m attr {\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m   key: \"Toutput_types\"\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m   value {\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m     list {\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m       type: DT_UINT8\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m       type: DT_UINT8\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m     }\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m   }\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m }\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m attr {\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m   key: \"output_shapes\"\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m   value {\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m     list {\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m       shape {\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m         dim {\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m           size: 28\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m         }\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m         dim {\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m           size: 28\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m         }\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m       }\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m       shape {\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m       }\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m     }\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m   }\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m }\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r187/187 [==============================] - 54s 272ms/step - loss: 0.2311 - accuracy: 0.9302 - val_loss: 0.0770 - val_accuracy: 0.9752\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/tmp/mnist_keras.ckpt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRdASNtRAbiN"
      },
      "source": [
        "Finally, evaluate using the Estimator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDNoiHiquX0A",
        "outputId": "4b2b8723-aebc-4886-996f-2ab3ddf8d5f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "stats = est.evaluate(val_data_creator, num_steps=10000 // batch_size)\n",
        "est.shutdown()\n",
        "print(stats)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function preprocess at 0x7fb761886dd0> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m Cause: Unable to locate the source code of <function preprocess at 0x7fb761886dd0>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m 2021-07-01 01:25:55.812739: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m op: \"TensorSliceDataset\"\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m input: \"Placeholder/_0\"\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m input: \"Placeholder/_1\"\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m attr {\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m   key: \"Toutput_types\"\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m   value {\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m     list {\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m       type: DT_UINT8\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m       type: DT_UINT8\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m     }\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m   }\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m }\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m attr {\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m   key: \"output_shapes\"\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m   value {\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m     list {\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m       shape {\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m         dim {\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m           size: 28\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m         }\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m         dim {\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m           size: 28\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m         }\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m       }\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m       shape {\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m       }\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m     }\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m   }\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m }\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m \r 1/31 [..............................] - ETA: 2s - loss: 0.0163 - accuracy: 1.0000\n",
            "\u001b[2m\u001b[36m(pid=436)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 6/31 [====>.........................] - ETA: 0s - loss: 0.0307 - accuracy: 0.9948\n",
            "11/31 [=========>....................] - ETA: 0s - loss: 0.0610 - accuracy: 0.9801\n",
            "16/31 [==============>...............] - ETA: 0s - loss: 0.0677 - accuracy: 0.9785\n",
            "21/31 [===================>..........] - ETA: 0s - loss: 0.0711 - accuracy: 0.9762\n",
            "26/31 [========================>.....] - ETA: 0s - loss: 0.0796 - accuracy: 0.9748\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.0845 - accuracy: 0.9718\n",
            "{'validation_loss': 0.08448926359415054, 'validation_accuracy': 0.9717742204666138}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyRtP6lqieej"
      },
      "source": [
        "Now, the accuracy of this model has reached 98%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nC4KhlHxXakk",
        "outputId": "5545fded-9daf-444a-e030-6633ce0c3f22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Stop orca context when your program finishes\n",
        "stop_orca_context()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Stopping orca context\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}